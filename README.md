# API LLM CV

API con LLM para anÃ¡lisis y procesamiento de CV usando FastAPI.

## ğŸš€ CaracterÃ­sticas

- **FastAPI** - Framework web moderno y rÃ¡pido
- **Endpoints LLM** - GeneraciÃ³n de texto y anÃ¡lisis de CV
- **DocumentaciÃ³n automÃ¡tica** - Swagger UI integrado
- **Multiplataforma** - Compatible con macOS, Windows y Linux

## ğŸ“‹ Requisitos Previos

### Python
- **Python 3.8+** (recomendado Python 3.11+)

### Verificar instalaciÃ³n
```bash
# macOS/Linux
python3 --version

# Windows
python --version
```

## ğŸ› ï¸ InstalaciÃ³n

### 1. Clonar el repositorio
```bash
git clone <tu-repositorio>
cd api-llm-cv
```

### 2. Crear entorno virtual (recomendado)

#### macOS/Linux:
```bash
python3 -m venv venv
source venv/bin/activate
```

#### Windows:
```bash
python -m venv venv
venv\Scripts\activate
```

### 3. Instalar dependencias
```bash
# macOS/Linux
python3 -m pip install "fastapi[standard]"

# Windows
python -m pip install "fastapi[standard]"
```

## ğŸš€ EjecuciÃ³n

### 1. Activar entorno virtual (si lo creaste)

#### macOS/Linux:
```bash
source venv/bin/activate
```

#### Windows:
```bash
venv\Scripts\activate
```

### 2. Ejecutar el servidor

#### macOS/Linux:
```bash
python3 -m uvicorn main:app --reload --host 0.0.0.0 --port 8000
```

#### Windows:
```bash
python -m uvicorn main:app --reload --host 0.0.0.0 --port 8000
```

### 3. Acceder a la API
- **API principal**: http://localhost:8000
- **DocumentaciÃ³n**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc

## ğŸ“š Endpoints Disponibles

### LLM API
- `POST /api/llm/generate` - Generar texto con LLM
- `GET /api/llm/models` - Listar modelos disponibles
- `GET /api/llm/health` - Estado de la API

### Ejemplos de uso

#### Generar texto:
```bash
curl -X POST "http://localhost:8000/api/llm/generate" \
     -H "Content-Type: application/json" \
     -d '{"prompt": "Analiza este CV", "model": "default"}'
```

#### Ver modelos disponibles:
```bash
curl http://localhost:8000/api/llm/models
```

## ğŸ”§ Desarrollo

### Estructura del proyecto
```
api-llm-cv/
â”œâ”€â”€ main.py              # AplicaciÃ³n principal
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â””â”€â”€ llm/
â”‚   â”‚       â””â”€â”€ routes.py  # Rutas de la API
â”‚   â””â”€â”€ __init__.py
â””â”€â”€ README.md
```

### Modo desarrollo
El servidor se ejecuta con `--reload`, por lo que se reiniciarÃ¡ automÃ¡ticamente cuando modifiques el cÃ³digo.

## ğŸŒ Acceso desde otros dispositivos

Si quieres acceder desde otros dispositivos en tu red local:
```bash
# macOS/Linux
python3 -m uvicorn main:app --reload --host 0.0.0.0 --port 8000

# Windows
python -m uvicorn main:app --reload --host 0.0.0.0 --port 8000
```

Luego accede desde: `http://[TU-IP-LOCAL]:8000`

## ğŸ› SoluciÃ³n de problemas

### Error: "command not found: python"
- **macOS**: Usa `python3` en lugar de `python`
- **Windows**: AsegÃºrate de que Python estÃ© en el PATH
- **Linux**: Instala Python con `sudo apt install python3` (Ubuntu/Debian)

### Error: "command not found: pip"
- **macOS/Linux**: Usa `python3 -m pip`
- **Windows**: Usa `python -m pip`

### Puerto 8000 ocupado
Cambia el puerto:
```bash
python3 -m uvicorn main:app --reload --port 8001
```

## ğŸ“ Licencia

Este proyecto es de uso personal para anÃ¡lisis de CV.
